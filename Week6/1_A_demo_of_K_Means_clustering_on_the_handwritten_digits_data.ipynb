{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1 A demo of K Means clustering on the handwritten digits data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN8Vq7CNObtJrnHmTmgtyKl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aincardz23/MachineLearningTraining/blob/main/Week6/1_A_demo_of_K_Means_clustering_on_the_handwritten_digits_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gIHYZNH89gU"
      },
      "source": [
        "**Load the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SwjGNnO88tf"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "data, labels = load_digits(return_X_y=True)\n",
        "(n_samples, n_features), n_digits = data.shape, np.unique(labels).size\n",
        "\n",
        "print(f\"# digits: {n_digits}; # samples: {n_samples}; # features {n_features}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG0ojtGA9Ft7"
      },
      "source": [
        "**Define our evaluation benchmark**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUcRuYw59Ls6"
      },
      "source": [
        "from time import time\n",
        "from sklearn import metrics\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "def bench_k_means(kmeans, name, data, labels):\n",
        "    \"\"\"Benchmark to evaluate the KMeans initialization methods.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    kmeans : KMeans instance\n",
        "        A :class:`~sklearn.cluster.KMeans` instance with the initialization\n",
        "        already set.\n",
        "    name : str\n",
        "        Name given to the strategy. It will be used to show the results in a\n",
        "        table.\n",
        "    data : ndarray of shape (n_samples, n_features)\n",
        "        The data to cluster.\n",
        "    labels : ndarray of shape (n_samples,)\n",
        "        The labels used to compute the clustering metrics which requires some\n",
        "        supervision.\n",
        "    \"\"\"\n",
        "    t0 = time()\n",
        "    estimator = make_pipeline(StandardScaler(), kmeans).fit(data)\n",
        "    fit_time = time() - t0\n",
        "    results = [name, fit_time, estimator[-1].inertia_]\n",
        "\n",
        "    # Define the metrics which require only the true labels and estimator\n",
        "    # labels\n",
        "    clustering_metrics = [\n",
        "        metrics.homogeneity_score,\n",
        "        metrics.completeness_score,\n",
        "        metrics.v_measure_score,\n",
        "        metrics.adjusted_rand_score,\n",
        "        metrics.adjusted_mutual_info_score,\n",
        "    ]\n",
        "    results += [m(labels, estimator[-1].labels_) for m in clustering_metrics]\n",
        "\n",
        "    # The silhouette score requires the full dataset\n",
        "    results += [\n",
        "        metrics.silhouette_score(\n",
        "            data,\n",
        "            estimator[-1].labels_,\n",
        "            metric=\"euclidean\",\n",
        "            sample_size=300,\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Show the results\n",
        "    formatter_result = (\n",
        "        \"{:9s}\\t{:.3f}s\\t{:.0f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\"\n",
        "    )\n",
        "    print(formatter_result.format(*results))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTSkgG6I9NbL"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "print(82 * \"_\")\n",
        "print(\"init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette\")\n",
        "\n",
        "kmeans = KMeans(init=\"k-means++\", n_clusters=n_digits, n_init=4, random_state=0)\n",
        "bench_k_means(kmeans=kmeans, name=\"k-means++\", data=data, labels=labels)\n",
        "\n",
        "kmeans = KMeans(init=\"random\", n_clusters=n_digits, n_init=4, random_state=0)\n",
        "bench_k_means(kmeans=kmeans, name=\"random\", data=data, labels=labels)\n",
        "\n",
        "pca = PCA(n_components=n_digits).fit(data)\n",
        "kmeans = KMeans(init=pca.components_, n_clusters=n_digits, n_init=1)\n",
        "bench_k_means(kmeans=kmeans, name=\"PCA-based\", data=data, labels=labels)\n",
        "\n",
        "print(82 * \"_\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1A54fiE9QZQ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "reduced_data = PCA(n_components=2).fit_transform(data)\n",
        "kmeans = KMeans(init=\"k-means++\", n_clusters=n_digits, n_init=4)\n",
        "kmeans.fit(reduced_data)\n",
        "\n",
        "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
        "h = 0.02  # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "\n",
        "# Plot the decision boundary. For that, we will assign a color to each\n",
        "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
        "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "# Obtain labels for each point in mesh. Use last trained model.\n",
        "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "# Put the result into a color plot\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.figure(1)\n",
        "plt.clf()\n",
        "plt.imshow(\n",
        "    Z,\n",
        "    interpolation=\"nearest\",\n",
        "    extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
        "    cmap=plt.cm.Paired,\n",
        "    aspect=\"auto\",\n",
        "    origin=\"lower\",\n",
        ")\n",
        "\n",
        "plt.plot(reduced_data[:, 0], reduced_data[:, 1], \"k.\", markersize=2)\n",
        "# Plot the centroids as a white X\n",
        "centroids = kmeans.cluster_centers_\n",
        "plt.scatter(\n",
        "    centroids[:, 0],\n",
        "    centroids[:, 1],\n",
        "    marker=\"x\",\n",
        "    s=169,\n",
        "    linewidths=3,\n",
        "    color=\"w\",\n",
        "    zorder=10,\n",
        ")\n",
        "plt.title(\n",
        "    \"K-means clustering on the digits dataset (PCA-reduced data)\\n\"\n",
        "    \"Centroids are marked with white cross\"\n",
        ")\n",
        "plt.xlim(x_min, x_max)\n",
        "plt.ylim(y_min, y_max)\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}